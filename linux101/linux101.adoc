Shell Scripting and the Linux Developer's Work Environment
==========================================================
:Author: Sashan Govender
:Email: sashang@gmail.com
:icons: font

//{include:footnotes.txt}
:fn1: footnote:[A bad habit new Linux users make is to login as root and proceed to do work +
as the root user. Login as a non-root user instead.]

:fn2: footnote:[A built-in is a command that Bash does not need to search for. Running it does not +
require a new process to spawn.]

:fn3: footnote:[apropos is an old-fashioned English word meaning 'something related to +
or connected to a topic.']

:fn4: footnote:[There is one company that sells a Unix like operating system that is remarkably profitable. Can you guess?]

:fn5: footnote:[Pronounced oo-boon-too, ubuntu is a Zulu word that literally means 'humanity' but is +
generally used to mean 'I am because you are'. A similar expression is 'no man is an island'.  They +
express the concept that a person cannot be without others, or you only are who you are because of +
others.]

:fn6: footnote:[GNU is a recursive acronym and stands for 'GNU is not Unix']

:fn7: footnote:['less is more' except when LESS_IS_MORE, then less really is more. This is a nerdy +
joke I made up.]

:fn8: footnote:['less is more' is a saying in English where we mean that something is better when +
there is less of it. For example a pizza with twenty toppings is not necessarily better than a pizza +
with five.]

:fn9: footnote:[POSIX.1-2008 http://pubs.opengroup.org/onlinepubs/9699919799/]

:fn10: footnote:[I haven't checked the source code but it's probably read by the [ program. I +
doubt the shell interpreter parses it.]

:fn11: footnote:[Also known as a 'kappie' in some parts of the world.]


== Preface
This document is intended to get the reader familiar with working on a Linux machine and therefore
any Unix machine. It's assumed that the reader is familiar with at least one other programming
language and understands concepts like functions, parameters, return values, types, scope and other
terminology that comes with programming. Differences between the Bourne Again Shell and the POSIX
compliant shell language will be marked with text like the following:

[NOTE]
.Bash Extension
======================
This stuff only works in Bash...
======================

This should help the reader differentiate between constructs that will work with one interpreter and
not the other.  In short, if you are a programmer that hasn't used Linux or any Unix based computer
before, didn't know what Bash stood for, or feel that references on the internet are not clear about
the boundary between features in Bash and those in the POSIX shell language, then this document is
for you.

Motivation for writing this came from years of working without a decent reference to work from or to
point other programmers to. Learning how to do things via results found on the internet would often
lead to shallow learning. There are many guides out there that are nothing more than a collection of
tricks that one can copy and paste but there doesn't seem to exist a shell scripting guide that
addresses the fundamentals of shell scripting. Shell scripting seems to fall in the gap of things
programmers learn as a side effect of doing their real job. When learning shell programming I was
puzzled by why if statements don't behave like if statements in other languages and why variables
seemed to have a mind of their own. Answers to these questions came not from cookbook aproaches to
shell scripting but from a better understanding of its fundamentals.

=== History
What do we mean when we say 'Linux'? It depends who you are talking to, but colloquially if someone
says 'I use Linux' they mean 'the Linux kernel and user level programs'. Technically speaking
'Linux' only refers to the kernel, and a kernel is only one piece of software that makes a computer
usable.  In 1991 Linus Torvalds released the first version of the Linux kernel. He is credited with
developing the kernel but he has had a small army of volunteers contributing to it. However the days
of kernel development being an unpaid hobby to scratch an itch that hippies engaged in are long
gone.  Contemporary kernel development is commercially driven using an open source software
development model. In other words companies pay developers to put code into the publicly available
kernel. A kernel alone does not make a usable operating system. The Free Software Foundation (FSF)
established the GNU {fn6} project and contributed immensely to the entire Linux ecosystem, not only
in the software that they have produced, but also at a legal and political level. The 'Free' in FSF
represents the freedom individuals have to modify the code. Most people think it means free of cost
but it's relative inexpense is a consequence of allowing anyone to modify the source code. The FSF
created the GPL (General Public License) that essentially stipulates that all other code
incorporating this GPL'ed code must also be released under the GPL and the code must be made
available to anyone who requests it. These conditions effectively ensure that source code covered by
the GPL is always available for anyone to modify. A side effect of this is that the cost of this
software is reduced. By the early 90's the GNU project had produced a lot of user level programs: a
compiler (gcc), a debugger (gdb), a text editor (emacs) and a shell (Bash) but their kernel (GNU
Hurd) was not ready. Linux was undergoing active development and the GNU tools were a natural fit on
top of the Linux kernel.

What impact has this collection of software that we collectively call Linux had? To answer this a
brief overview of Unix is required. Prior to the existence of Linux based systems there were many
commercial Unix distributions. Even Microsoft, at one point in time, sold a Unix variant called
Xenix. The original Unix was first implemented at Bell Laboratories (part of AT&T) by Ken Thompson
in 1969. By 1979 he had moved to the University of California at Berkeley and there produced another
Unix distribution, the Berkeley Software Distribution (BSD). By the 80's various Unix
implementations were spreading throughout universities and commercial distributions from companies
like AT&T and Sun were available. By the 90's USL, a vendor of the original Unix system developed at
AT&T, clashed with of a Berkeley Software Design, Inc, a vendor of a BSD system. USL claimed that
BSDi misappropriated code and filed a lawsuit against them creating uncertainty in the market.
Customers were unsure who would win the lawsuit so refrained from purchasing either product and
turned to the GNU/Linux combination to provide them with a Unix like operating system. This was the
beginning of the end for the majority of commercial Unix vendors. The market now had a new player
that was low cost and unencumbered of lawsuits.  Vendors of commercial Unix products (SCO Unixware,
IBM AIX, Microsoft Xenix, SUN, SGI Irix) are no longer in business or have had their market share
eroded, or have discontinued their product line. As a result there are not many vendors of
commercial Unix like systems that are profitable {fn4}.

=== Linux distributions
A kernel in isolation is useless. As a human I still need a way to interact with the machine. This
is where Linux distributions come into play. They package a set of core programs along with the
Linux kernel that make a computer usable. Some of the earlier distributions that are still around
are Redhat, Debian, Suse and Slackware. Slackware is unique because it is a source distribution, so
you have to compile the programs you want yourself, and the package management tool provides no
dependency checking. Distributions like Redhat and Debian are more user friendly and are binary
distributions (you install pre-compiled binaries of the software) and come with dependency
management. There are also distributions that have a hybrid approach, for example Gentoo or Funtoo
which are source distributions with dependency management and distributions that are derivatives of
an existing distribution, like Ubuntu {fn5} which is derived from Debian.  Unfortunately there is a
lot of variation in the dependency management systems so the commands that install a package on
Redhat won't work on Debian. This explains why many tutorial documents will say 'install the
development package for libxml2' instead of explicitly stating the command 'yum install
libxml2-devel' because they expect the user to understand how to install packages using their
distribution and it's too much work to list the many alternative ways one could install a package
for the many distributions.  To get an overview of the current Linux distributions have a look at
http://www.distrowatch.com[Distrowatch]. It lists the distributions and ranks them based on
popularity.

Although the specific mechanics of installing packages on a Linux distribution can vary there is a
still a common set of principles and guidelines that all Linux distributions will follow.
Understanding these general principles will make working with a Linux system (or for that matter any
Unix based system) much easier.

Any desktop Linux distribution, except the most esoteric, will have the following.

==== Shell
A shell (sh, bash, csh, zsh) is what lets a user talk to the computer via the command line.  The
Bourne Shell (sh) was released in 1977.  It suffices to say for now that csh was designed for
interactive use but the Bourne Shell had more features for automating tasks via scripts. As a result
there are now two families of shells, those derived from csh and those derived from sh. Scripts
written for one won't work on the other and because the languages are quite different and attempts
to make a non-trivial script portable are doomed to fail. It makes more sense, if presented with a
script in csh for example, to run it in the csh command line interpreter. The Bourne Shell
scripting language became the POSIX standard and of all the interpreters that can run Bourne Shell
scripts, Bash became the most popular. As a result, Bash is everywhere Linux is.

==== X Windows
This is the basis of all graphical user interfaces. KDE and GNOME are both desktop managers that lie
with X Windows through them. Server distributions will not package X Windows since there is no need
for a GUI on a server that runs without a monitor. Machines without a monitor are sometimes called
headless and you interact with them via the shell over the network using ssh. Some servers will
install the server side components of X Windows to allow users to remotely connect and have a GUI to
work with.

==== Text Editors
A text editor on Linux is a system administrator's or developer's best friend. You will spend most
of your working hours inside one so it's best to learn one like you know the back of your hand. Vi
is the most common text editor found on Linux systems, however for programming work learning to use
Vi Improved (Vim) or EMACS will pay off. Both Vim and EMACS are customizable. Vim is customizable
via it's insane VimL language and EMACS via EMACS Lisp. They do not require a GUI so editing files
on a headless server over ssh is possible. Since you're forced to use your fingers on a keyboard you
end up doing things faster than you would if you used a mouse. More user friendly terminal editors
are nano and pico. If you are running Gnome then there is gEdit and KDE has Kate.

== First Steps with the Bourne Again Shell

The Bourne Again Shell (Bash) is derived from the Bourne Shell. From a programming language
perspective Bash is an untyped dynamic language. Essentially all data (i.e. function parameters,
return values) are strings, hence there is no type checking and you can quite easily compare
something that you intend to be text with something that you intend to be a number. From the
viewpoint of a computer scientist this is bad; the goal of a compiler is to prove at compile time
that your program does what it is meant to do and untyped languages make this difficult. From the
pragmatic viewpoint of an engineer or system administrator who needs an answer now, using an untyped
language like Bash allows one to get a result quickly with the expense of the programmer having to
remember what the data in the program represents. An interesting point of comparison is Microsoft's
Monad (now known as Powershell) which is used on Windows to automate tasks. It is a strongly typed
dynamic language. Function parameters and return values are not simple strings but fully fledged
objects with a distinct type. Another issue with Bash is performance. Bash scripts run through an
interpreter and are not compiled. Frequently a Bash program is launching other programs to do some
work, and then doing string manipulation on the results. Unlike programming in any other language
there are no libraries of functions that Bash ships with or that you can download and use from your
scripts. Instead Bash scripts frequently invoke binaries included under /bin and /usr/bin on your
Linux machine and these binaries play the role that a library of functions do in other languages.

The easiest way to begin using Bash is to start your Linux machine and after logging in {fn1} open
up a terminal, for example gnome-terminal, so that you are presented with the command prompt.  Check
that you are running `bash` by typing the following:

------------------
$ echo $SHELL
/bin/bash
------------------

TIP:
The `$` at the start of the line (not in front of `SHELL`) is where you type input. It is called the
command prompt. You do not need to type it.

If it says something other than `/bin/bash` then start bash by typing `bash` at the prompt and
hitting enter. In the unlikely event that it can't find bash then it is probably not installed on
your Linux distribution and you'll have to install it yourself.

TIP:
You can change your default login shell by running `chsh`.

To see what files are in the current directory you are in type `ls`. The following is what I see in
my home directory.

---------------
bash-4.3$ ls
bin  code  Desktop  Downloads  tmp
bash-4.3$
---------------

To see the name of the current directory type `pwd`.

---------------
bash-4.3$ pwd
/home/sashan
bash-4.3$
---------------

* Note that on Linux individual directories in a path name are separated by a forward slash `/`.

Type `ls -a`.

---------------

sashan@arch-vm: ~  $ ls -a
.              .cabal        Downloads
..             .cache        .esd_auth
.adobe         code          .gem
.bash_history  .config       .ghc
.bash_logout   .dbus         .gitconfig
.bash_profile  Desktop       .gresolverrc
.bashrc        .dmenu_cache  .gvimrc
bin            Documents     .hgrc
sashan@arch-vm: ~  $
---------------

This shows hidden files. Hidden files are prefixed with a `.`. Typically application
configuration files for a user are hidden and stored in the users home directory. Note the special
files `.` and `..` that are the first two entries. A `.` on it's own means 'this current directory'.
The `..` means 'the parent directory'. `.` and `..` can be used as arguments on the command line.
For example, a common action is to change to the parent directory using `cd ..`.


Type `ls -l`.

---------------
sashan@arch-vm: ~  $ ls -l
total 204712
drwxr-xr-x  2 sashan users      4096 Feb 11 14:37 bin
drwxr-xr-x 20 sashan users      4096 May 18 15:09 code
drwxr-xr-x  2 sashan users      4096 Dec  2 08:20 Desktop
drwxr-xr-x  3 sashan users      4096 Mar 25 18:13 Documents
drwxr-xr-x 11 sashan users      4096 May 20 22:41 Downloads
-rw-r--r--  1 sashan users 209590557 Mar 10 23:35 suse12.tar.bz
drwxr-xr-x  3 sashan users      4096 Mar 24 11:39 tmp
drwxr-xr-x  3 sashan users      4096 Dec  9 21:06 writing
sashan@arch-vm: ~  $
---------------

This is the most useful way to find out about the files in a directory. The 1st column are the file
permissions (see <<file_system>>). File permissions will be explained later. The next column is a
count of the number of hard links to this file or directory (see <<file_system>>). The third and
fourth are the user and group of the file.  The fifth is the byte count. The date field is the last
time the contents of the file was changed.

In the tradition of other programming language guides, this document is no different and the next
example is what  `hello world` looks like in Bash. Simply type the following at the command prompt.

------------------
$ echo "hello world"
hello world
------------------

However if you want to be able to recall the program and execute it at a later date you should save
it to a file. This file is called a 'script' or 'Bash script' or 'shell script'. These terms are
used generally used interchangeably. The following is what a file should look like.

[source, bash]
------------------
#!/bin/bash

echo "hello world"
------------------

Save the text above to a file and try executing it. You will have to set the execute flag on the
file to allow it to execute.

------------------
$ chmod +x hello-world.sh
$ ./hello-world.sh
hello world
------------------

* Note that the '#!' (pronounced 'sha-bang' - yes it's funny) needs to be at that position in the
  first line of script. It tells the operating system loader which program to run when starting the
  script. In this case when you start the script the program loader starts the program `/bin/bash` and
  passes it the script `hello-world.sh` effectively doing this: `/bin/bash hello-world.sh`.

* The use of chmod and file permissions are explained in <<file_system>>. It suffices to say for now
  that this line sets the execute bit on the file. Without it the operating system would not execute
  the following line as intended.

* This is where the execution of the script starts. Note the use of dot-slash `./`. In general on
  Linux we have to specify the full path to the program that we want to run if the directory it
  is in is not in the PATH environment variable.

=== Environment Variables
We've already seen two examples of environment variables, SHELL and PATH. They have been introduced
without a general explanation about environment variables. An environment variable is essentially
something that a program has access to without having to define it. They are defined by the program
launching your program. To see the list of environment variables present in the shell type `env` at
the prompt. There will probably be a long list of them but the important ones are:

* `PATH` - this is a list of directories that are searched for executable binaries that match the
  name given by you on the command line when you want execute a program. Notice that the current
  working directory is not in the path (which is the opposite from Windows). This explains why the
  to run the script in the example above we had to prefix the name with `./`.
* `HOME` - this tells you the path to your home directory.
* `SHELL` - this tells you the path to the shell that is started by default.
* `USER` - your user name.
* `EDITOR` - the name of your editor. Often other programs will read this variable to know which
  editor to use. For example `git` uses this to decide which editor to start when you have to write
  the commit log message.

You've already seen how to use the contents of the these variables when you typed `echo $SHELL`
above. The `$` tells the shell to perform 'parameter expansion' and the value of the variable is
substituted in place. A common idiom to change to your home directory is:

------------------
cd $HOME
------------------

Alternatively the `~` can be used in place of `$HOME`.

To set an environment variable:

----------------
$ myvar=asda
$ echo $myvar
asda
----------------

`myvar` will only be available for use in the current process. In other words programs you launch
from the shell will not have access to `myvar`. To change it so that other processes inherit the
variable use the built-in {fn2} `export`.

----------------
$ export myvar=asda
----------------

To remove the variable use `unset`.

-----------------
$ unset myvar
-----------------

== Selection
Not surprisingly Bash has `if` statements that allow you to make a selection. The complexity comes
in the various expressions that you can place after the `if`. However, before detailing if
statements, we need to define what true and false in shell programming is. This might be surprising
if you are familiar with other programming languages.

=== True and false
In shell programming 0 is interpreted as true. This is different from C where 0 is always
false. This explains why when a program that successfully terminates returns 0 to the shell. To
demonstrate this there are two programs called `true` and `false` that return `0` and `1` to the
shell respectively.

-----------
$ true
$ echo $?
0
$ false
$ echo $?
1
-----------

* Note that the special variable `?` is set to the result returned by the last program executed.

As you can see above true is `0` and false is `1`.

=== If Statements
A typical `if` statement starts with `if` followed by a program to run.

----------------
if true; then
  echo "true"
fi
----------------

Note that it's common to write if statements like this as well:

----------------
if true
then
  echo "true"
fi
----------------

This is a style choice and does not change the meaning of the statement. The guideline, as with all
other coding style conventions, is to adopt the style that exists in the script you are editing.

A more useful example is to use the program `grep` to find text in a file.

[source, bash]
-----------------
#!/bin/sh

if grep "alias" ~/.bashrc; then
  echo "yes"
fi
-----------------

`grep` is a program the performs a regular expression search on a file and then outputs the line
containing the regular expression. Regular expressions will be explained more fully later and the
example above shows a simple regex `alias` where we know exactly what we are looking for, and so
input the characters literally. If `grep` finds a match it will return 0. If no match is found it
returns 1. Note that you do not have to explicitly test that the return value is 0 or 1.

You might see `if` statements written like this:

[source, bash]
-----------------
#!/bin/bash

if grep "alias" ~/.bashrc
then
  echo "yes"
fi
------------------

There's nothing wrong with it. If you have to edit a shell script adopt the style already in use.
Don't mix styles.

We also need to be able to test the value of variables. The example below uses the `test` command to
compare integers.

[source, bash]
----------------
#!/bin/bash

myvar=1
if test $myvar -eq 1; then
  echo one
fi
----------------

The `test` command can be used interchangeably with `[`. For example,

[source, bash]
----------------
#!/bin/bash

myvar=1
if [ $myvar -eq 1 ]; then
  echo one
fi
----------------

The only difference is that `[` requires a closing `]`. Also note that you need the space after `[`.
For example this will not work:

[source, bash]
----------------
#!/bin/bash

myvar=1
if [$myvar -eq 1]; then
  echo one
fi
----------------

Now the interpreter things that `[$myvar` is a command  to execute with the parameters `-eq` and
`1]`. This also explains why when defining a variable you do not place a space between the variable
name and the `=`.

-----------
$ myvar = 1
-bash: myvar: command not found
-----------

Bash thinks that `myvar` is a command and tries to execute it. It does not find it in the `PATH` so
it fails.

Note that `-eq` is intended to be used to compare integers and not strings. To test for equality
between strings use `=`.

[source, bash]
----------------
#!/bin/bash

myvar=something
if [ "$myvar" = "something" ]; then
  echo "equal"
fi
----------------

Note the use of `"` around `$myvar`. This is needed if the value of `myvar` contained spaces. For
example this will not do what you expect.

[source, bash]
----------------
#!/bin/bash

myvar="one two"
if [ $myvar = "one two" ]; then
  echo "equal"
fi
----------------

It needs to be written like this:

[source, bash]
----------------
#!/bin/bash

myvar="one two"
if [ "$myvar" = "one two" ]; then
  echo "equal"
fi
----------------

A good rule of thumb is to always use a `"` when doing string comparisons.

`test` or `[` can take a variety of options. A lot of them are to check different properties of a
file. For example the code below tests for the existence of a file:

[source, bash]
----------------
#!/bin/bash

if [ -f $HOME/.vimrc ]; then
  echo "yes"
fi
----------------

Rather than list the parameters `test` can take in this document, now is probably a good time to
start getting used to using 'man pages'. Type `man test` at the command line. For more about 'man
pages' see <<man_pages>>. You will notice that there are a lot of operators for testing properties
about files and explaining all of them will require information from <<file_system>>.

Their are numerous file test commands. A few are worth explaining here but others require more
knowledge about the Linux filesystem (see <<file_system>>).

* `-f` will test for regular files. In general this is a file that you use to store information,
  like a text file or word document. It doesn't include directoriess or special files.

* `-e` will test for the existence of any file including special files.

* `-d` tests if the file exists and is a directory.

* `-a` performs logical `and`.

* `-o` performs logical `or`.

Now consider this:

[source, bash]
-----------------
#!/bin/bash

if [ 0 ]; then
  echo "I should see this!"
fi
-----------------

Remember that `0` is interpreted as true in shell programming. Therefore running this script should
echo the text to the terminal. However if you run it nothing will be written to the terminal.  What
is going on? Is `0` true or false? To answer this remember that `[` is a synonym for `test` and is a
command that is executed and not a language construct that you find in other languages. This means
the program above can be written like.

[source, bash]
-----------------
#!/bin/bash

if test 0; then
  echo "I should see this!"
fi
-----------------

Now it's clear that the command `test` is being executed with the single argument `0`. How can we
find out what test does with its arguemnts? Remember the man pages mentioned above? Now is a good
time to use it. In the shell type

-----------
$ whatis test
test (1)             - check file types and compare values
test (1p)            - evaluate expression
Test (3perl)         - provides a simple framework for writing test scripts
-----------

It shows the man pages related to the `test` commands installed on the host. Type

------------
man 1p test
------------

This will bring up the POSIX programming guide for the `test` command. The key sentence from the
document is:

----------------
1 argument: Exit true (0) if $1 is not null; otherwise, exit false.
----------------

Therefore, with a single argument, `test` will always return `0` which in shell programming is true,
which is why expressions like

----------
if [ 0 ]
----------

will always evaluate true.

However the anwer opens another question, namely what is `null` in shell programming? A quick
example should show this.

--------------
$ test $undefined
$ echo $?
1
--------------

`undefined` has not been set to any value and so the shell treats it as null. Unlike other languages
Bash does not have a literal token that represents 'null'.  `0` is not the same as `null`.
Additionally the interpreter will not issue a runtime error if it is told to perform parameter
expansion on an undefined variable. Another way that null is represented in Bash is via a 0 length
string, or an empty string.

---------------
$ empty=""
$ test "$empty"
$ echo $?
1
---------------

If you know that the variable you are dealing with is a string then you can also use the `-z`
operator to test it.

------------------
$ empty=""
$ if [ -z "$empty" ]; then echo "null string"; fi
------------------

A non-null string can be tested for using the `-n` operator.

------------------
$ something="something"
$ if [ -n "$something" ]; then echo "not empty"; fi
------------------

==== and or not
The test program takes special arguments that represent `and`, `or` and `not`. These are shown
below:

.not
------------
if [ ! 0 ]
-----------

.and
------------
if [ 1 -a 2 ]
------------

.or
------------
if [ 1 -o 2 ]
------------

`not` is simply a `!`. `and` you pass the argument `-a` to test. `or` you pass test the `-o` argument.
In shell programming it's best to think about the `[` not as a keyword or and operator that the
language consumes as part of it's grammar. It's a command, a synonym for `test`, that like any other
command takes a list of parameters. The closing bracket `]` is just syntactic sugar {fn10}.

==== && and ||
These operators *are* part of the shell language, but they do not work as you might expect them to.
For example this:

------------
if [ 1 || 2 ]
------------

will cause the interpreter to stumble. What's going wrong here? Doesn't `||` just mean `or`? To
understand this remember that `[` is synonym for `test`. Can `test` take `||` as an argument?
Checking the man pages for test shows that it cannot. Therefore the problem is `test` does not know
what a `||` is. However the following works:

------------
if true || false; then echo "yes"; fi
------------

In this context the `||` operator joins 2 command lists. Similarly the `&&` operator can be used to
join 2 command lists with a logical and. The interpreter will perform short circuit evaluation. For
example the following is an idiom you might see used from time to time in shell scripts.

------------
somecommand || exit 1
------------

If `somecommand` fails then the call to `exit 1` is made and the script will terminate with a return
code of `1`. Remember that in shell programming return codes of `0` are good and non-zero return
codes are bad. If `somecommand` returns 0 then the `exit 1` will not be performed due to short
circuit evaluation kicking in.

[NOTE]
.Bash Extension
======================
Bash adds a operator `[[` and this can change how tests are written. If portability is a concern
this operator should not be included in your scripts. The operators that work with `test` also work
with `[[`. It adds features that make conditional expressions more C like. For example there is no
need to enclose string variables within `"`.

[source,bash]
------------
#!/bin/bash

myvar="one two"
if [[ $myvar = "one two" ]]; then
  echo yes
fi
------------

will do what you expect and echo `yes` to stdout.

C-like operators `&&` and `||` can be used. Note that in this context the meaning of the operators
is different from when they are used to join command lists.
======================

=== Case Conditional Construct

Case statements are another way to perform selection but the various guards in the case construct
can be patterns.

The construct looks like this:

[source,bash]
------------
#!/bin/bash

myvar=$1
case $myvar in
  one)
    echo 1;;
  two)
    echo 2;;
  *)
    echo "undefined"
esac
------------

The last guard in the case construct is how the default case is handled in shell programming. `*` is
a pattern that matches any string.

The `?` below means match any character. It will match `one` or `o2e` etc...
[source,bash]
------------
#!/bin/bash

myvar=$1
case $myvar in
  o?e)
    echo 1;;
  two)
    echo 2;;
  *)
    echo "undefined"
esac
------------

To match literally enclose the pattern in `"`. For example:

[source,bash]
------------
#!/bin/bash
case $myvar in
  "o?e")
    echo 1;;
  two)
    echo 2;;
  *)
    echo "undefined"
esac
------------

will match the string "o?e" only.

== Iteration
Describe iteration

=== While
While examples

=== For
For examples

=== Recursion
Recursion examples

== Process Management

Stuff about pipes, redirection, async background init, fg, bg.

[[regexp]]
== Regular Expressions

Regular expressions tend to be the bane of every new programmer's life because a typical expression
looks like noise. You just have to retrain your brain to see the characters and not expect words
with spaces as delimiters. After some practice and learning what the metacharacters mean it becomes
intelligible. The basic idea behind regular expressions is that it's a pattern matching language.
You describe a pattern using the regular expression syntax and that matches a variety of concrete
realizations of that pattern.

In this chapter we will illustrate the application of the POSIX regular expressions, both the basic
and extended variants, using the programs `grep` and `sed`. Since we are working on Linux there are
some extensions that the GNU foundation have added to `grep` that are not part of the POSIX
standard. These will be noted so you can write portable shell scripts that work on a variety of Unix
like operating systems. `grep` stands for `general regular expression` but it's often used as a verb
in sentences. For example an engineer might often say 'I grepped for the string' when searching for
some text in a file. `sed` stands for `stream editor`. It allows you to match text using regular
expressions and then perform a transformation, like capitalization or substitutioon, on the matched.
`grep` only searches for a pattern in each line of a file and does not allow one to change the text.
It prints the line containing the match.

=== Basic Expressions

A simple expression is one that contains no special characters and matches literally. For
example,

------------------------------
$ grep "is" summertime-ending.txt
“It used to be that he, John, had too little employment. Now that is about to change. Now he will
have as much employment as he can handle, as much and more. He is going to have to abandon some of
his personal projects and be a nurse. Alternatively, if he will not be a nurse, he must announce to
his father: I cannot face the prospect of ministering to you day and night. I am going to abandon
you. Goodbye. One or the other: there is no third way.”
------------------------------

`grep`, without any parameters to modify its behaviour, will match the pattern in each line and if a
match is found, it will print the whole line. As you can see from the example above it matches where
`is` is part of a word.

[NOTE]
.GNU Extension
=================================
Sometimes what people want to find is the line with that whole word on it, and not the lines where
the word is part of another larger word.  Unfortunately the POSIX specification for basic regular
expressions doesn't define a metacharacter that represents word boundaries. To do this use `grep
-w`.
-------------------------------
$ grep -w "is" summertime-ending.txt
“It used to be that he, John, had too little employment. Now that is about to change. Now he will
have as much employment as he can handle, as much and more. He is going to have to abandon some of
you. Goodbye. One or the other: there is no third way.”
-------------------------------

One can also use the special characters `\<` and  `\>` that mark the start and end of a word.

-------------------------------
$ grep "\<is\>" summertime-ending.txt
“It used to be that he, John, had too little employment. Now that is about to change. Now he will
have as much employment as he can handle, as much and more. He is going to have to abandon some of
you. Goodbye. One or the other: there is no third way.”
-------------------------------

=================================

==== Special characters

The Dot or Period `.`::

The special character `.` means match any character. Thus when used in the following regex `hi.` it
will match `hit` or `him` or a `hi`  followed by a space. Note that only the first 3 letters are
matched in `hilt` and similarly in a word like `shilling` it's only the letters at positions 2,3,4
that are matched.

The Asterisk or Kleene Star `*`::

The asterisk (or Kleene star) matches 0 or more of the preceeding character. For example `a*`
matches `a` or `aa` or `aaa`. The match is greedy meaning that it will match the largest possible
number of characters.

The Circumflex or Hat {fn11} `^`::

The circumflex (or hat) matches the start of a line. The expression `^you` will only match `you` if
it is at the start of a line.

The Dollar `$`::

The dollar matches the end of a line.

Parentheses `\(` and `\)`::

Parentheses group sub-expressions into a group that can be refered to within the same expression using
`\n`, where `n` is the nth group in the entire expression.

Braces `\{` and `\}`::

These braces are used to form interval expressions. An interval expression modoifies the number of
times the preceding expression needs to match. For example `\{1,3\}` says match the preceding
expression 1 to 3 times. Again, matching is greedy so if the option exists to match 1 or 2 or 3
repetitions of the preceeding pattern, the largest valid match is returned.

Square brackets `[` and `]`::

The square brackets form a bracket expression and are used to create a set of characters where the
sequence does not matter.  For example the expression `[ab]` matches strings "a" or "b".
Importantly the characters `.`, `*`, `[`, and `\` lose their special meaning within bracket
expressions. Therefore expression like `[a.b]` will match "a" or "." or "b" but not any other
character. The restrictions on `[` and `\` prevent one from nesting bracket expressions.


=== Extended Regular Expressions

Extended regular expressions include the special characters listed above and introduce the following special characters:

Question mark `?`::
This matches 0 or 1 of the preceding expression.

Plus `+`::
This matches 1 or more of the preceding expression.

Bar or Vertical Line or Pipe `|`::
A regular expression that consists of two expressions separated by this symbol matches a string that
contains one of the expressions.

Confusingly if using extended regular expressions you don't need to escape the `{` or the `(`. For
example this ERE `(ab)` is equivalent to this BRE `\(ab\)`. In other words the parentheses have
special meaning by default, without a backslash preceding it. To search for parentheses and braces
literally use a backslash in an ERE. For example `\(ab\)` matches `(ab)`

`grep` by default uses BRE but passing `-E` to it will enable extended regular expressions.

=== Putting it all together.

Now that we've covered the theoretical part of regular expressions lets use them in some examples.
In the examples we will use the ERE syntax. In addition to `grep` we will also use the program `sed`
to search and replace.


.Find events in the syslog that happened around the 30 minute mark of the hour

============================
Assuming that a time stamped line the log file looks like:

--------------------
Jan 01 17:35:45 phoenix NetworkManager[351]: <info>    server identifier 192.168.0.1
---------------------

This will print out events timestamped within 5 minutes of the 30 minute mark.

grep -E "[0-2][0-9]:(2[5-9]|3[0-5]):" logfile

============================

.Swap function parameters

============================

Assume you have a function declaration like this:

[source, c]
-------------
void foo(int a, char c);
-------------

that has changed to this:

[source, c]
-------------
void foo(char c, int a);
-------------

now calls to the original function will no longer compile due to a type mismatch. You need to
rewrite them so that the char variable is in the first parameter position. Can we solve this using a
regex? Yes we can! Consider the following examples of function calls.

[source, c]
--------------
foo(a, b);
foo(someval, someval1);
foo(asok_askdjas, pioqw_asd);
foo(some_char, some_int);
--------------

The following expression given to `sed` will swap the parameters.

--------------
sed -r -e "s/foo\(([0-9a-zA-Z_ ]+), ([0-9a-zA-Z_ ]+)\);/foo\(\2, \1\);/"
--------------

It probably deserves some explanation. `-r` turns on extended regular expressions. `-e` is the sed
script to run. The first parameter in the sed script `s` stands for `substitute`. It tells sed to
expect a search string and a replacement string. The second character (the first forward slash) `/`
is a delimeter. It delimits the search string from the replacement string and the end of the script.
sed accepts any character for a delimiter. We could have rewritten the above expression using an `@`
symbol instead:

--------------
sed -r -e "s@foo\(([0-9a-zA-Z_ ]+), ([0-9a-zA-Z_ ]+)\);@foo\(\2, \1\);@"
--------------

After the first delimiter the expression to find is given. This is just the function name, `foo`,
followed by an opening parenthesis `\(` that we need to escape with a backslash because we are
using extended regular expressions and we want to match literally. Then the next parenthesis `(` is
special and marks the beginning of the first grouped sub-expression. A bracket expression describing
the set of characters permitted in a C identifier follows. Then we quantify it with a `+`, meaning
that we want 1 or more of the preceding characters. Then we close the first group with a `)`. The
next expression is similar and matches the second parameter of the function. It is also enclosed in
group. Then we hit the delimiter that marks the end of the search expression and the beginning of
the replacement expression. The replacemanet expression simply makes use of the grouped expressions
in the search expression, and refers to the second and first groups using `\2` and `\1`
respectively. There are some shortcommings with the above expression. One is that it relies on
uniform spacing between identifiers and tokens in the code that is being transformed. For example it
will not match this:

--------------
foo (some_char, some_int);
--------------

because of the space between the `foo` and `(`. There are a few ways to remedy this:

- you could rewrite the expression to handle whitespace or
- strip the whitespace then process the functions.

============================
[[file_system]]
== Permissions and the Linux File System

Insert text about permissions

== Important Programs

This section covers programs that are insanely useful when shell programming.

[[man_pages]]
=== man
'man pages' is short for 'manual pages' and they are a set of documents that describe functions and
commands on Linux system. Getting used to reading them will allow you to become more self-sufficient
when working in a Linux environment. In the shell if you type `man test` you will be presented with
text about the `test` command. It's displayed in what's known as a `pager`, the default pager being
`less`. See <<less>> for the key bindings one can use to navigate. It's worth practising using these
keys until they are embedded in your subconscious and you don't have to think about it.

If you type `man man` you will get a description about the man pages themselves. Man pages were
originally divided into 8 categories. There might be a 9th category depending on your Linux
distribution, but the early Unix implementations had 8. The categories are a bit archaic and not so
relevant. For example category 6 is for games. However the important thing to note is that the
category numbers can be used as parameters to `man` itself.

For example, say you wanted to find out about `printf` in the C standard library. You might type
`man printf` at the command prompt. This will bring up some text about the `printf` command that is
a shell built-in, and not the information you want about the C library function. However, category 3
is for library functions, so typing `man 3 printf` will show you the man page for the `printf`
function.

Searching the man pages can be accomplished by two programs: `apropos` {fn3} or `whatis`. For example, if
you want to find out how to use `fclose`, then on my machine typing `apropos fclose` results in:

---------------------
$ apropos fclose
fclose (3)           - close a stream
fclose (3p)          - close a stream
fcloseall (3)        - close all open streams
pdfclose (1)         - open or close a PDF file viewer
TIFFClose (3tiff)    - close a previously opened TIFF file
zzip_disk_fclose (3) - openening a file part wrapped within a (mmapped) zip archive
zzip_entry_fclose (3) - open a file within a zip disk for reading
zzip_fclose (3)      - ...
---------------------

and `whatis fclose` results in:

---------------------
$ whatis fclose
fclose (3)           - close a stream
fclose (3p)          - close a stream
---------------------

`apropos` matches any text in the title or short description and `whatis` matches only exact
matches. Note the number in the parentheses. This is the category that the document appears in. For
example typing `man 3p fclose` will bring up the man page in that category pertaining to that
command or function name. The `p` in `3p` is for Posix and is a way of extending category `3`. In
other words, instead of creating a category 10 for documentation about Posix functions, they added
them to the existing functions category `3` and added the suffix `p`.

[[less]]
=== less
`less` is a pager. A pager lets you read text and scroll up and down between pages. The problem it
solved hardly exists theses days, but in the past terminals rarely supported scrolling, so once the
text scrolled passed the top line on the screen you could not 'page up' to read it again. A pager
buffered this text so that you could 'page up' and read it. Another pager is `more` but `less` is
better. The man page for `more` recommends using `less`. In fact the maxim 'less is more' really
does apply {fn7} {fn8}. It's worth memorizing the key bindings to move around in `less`.

.Key bindings
[width="40%",frame="topbot",options="header,footer"]
|======================
|Key      |Action
|j        |down
|k        |up
|/        |forward incremental search
|?        |backward incremental search
|ctrl+u   |half page up
|ctrl+d   |half page down
|======================

[[sed]]
=== sed
Describe sed

[[awk]]
=== awk

Describe awk

[[grep]]
=== grep
TODO


[[cat]]
=== cat
TODO

[[find]]
=== find
TODO

[[xargs]]
=== xargs

TODO

[[cat_tac]]
=== cat and tac

TODO

[[tail_head]]
=== tail and head

TODO

